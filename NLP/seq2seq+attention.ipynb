{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eileen Zhang 2020/8/29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrIeLqfhRZmf"
   },
   "source": [
    "# Rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eo9vB75kRZmh"
   },
   "source": [
    "数据集  \n",
    "$$\\big\\{\\left(\\mathbf{x}_t,\\mathbf{y}_t\\right)\\big\\}_{t=1}^T$$\n",
    "其中，  \n",
    "第$t$时刻输入数据$\\mathbf{x}_t=\\left(x_t^{\\left(1\\right)},x_t^{\\left(2\\right)},\\dots,x_t^{\\left(n\\right)}\\right)^{\\top}\\in\\mathbb{R}^n,$   \n",
    "第$t$时刻输出数据$\\mathbf{y}_t=\\left(y_t^{\\left(1\\right)},y_t^{\\left(2\\right)},\\dots,y_t^{\\left(m\\right)}\\right)^{\\top}\\in\\mathbb{R}^m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1J-V2cuRZmk"
   },
   "source": [
    "循环神经网络模型结构\n",
    "$$\\begin{align} \n",
    "\\left\\{ \n",
    "\\begin{array}{**lr**} \n",
    "\\mathbf{h}_t=f\\left(\\mathbf{W}\\centerdot\\mathbf{x}_t+\\mathbf{U}\\centerdot\\mathbf{h}_{t-1}\\right) & \\\\ \n",
    "{\\mathbf{y}}_t=f\\left( \\mathbf{V}\\centerdot\\mathbf{h}_t\\right) \\\\ \n",
    "\\end{array} \n",
    "\\right. \n",
    "\\end{align} $$  \n",
    "其中，$\\mathbf{h}$为隐状态，$f\\left(\\cdot\\right)$为非线性激活函数，$\\mathbf{U},\\mathbf{W},\\mathbf{V}$为模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GYwBM1aRZmn"
   },
   "source": [
    "![rnn.gif](../data/rnn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJxXei3URZmp"
   },
   "source": [
    "**GRU 算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1lwZSgARZmr"
   },
   "source": [
    "![gru.png](../data/gru.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJxyDAeTRZmt"
   },
   "source": [
    "![RNN-vs-LSTM-vs-GRU-1024x308.png](../data/RNN-vs-LSTM-vs-GRU-1024x308.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxSeTfRNRZmz"
   },
   "source": [
    "**units for gru** : units 它们本身并行，并没有什么联系，然后它们通过最后的softmax求导时产生了联系，仅此而已。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LH0INQ5SRZm2"
   },
   "source": [
    "![gru_unit.png](../data/gru_units.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Olzw88oRZm3"
   },
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h84mCvPYRZm5"
   },
   "source": [
    "![seq2seq.png](../data/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4Ys4LgqRZm7"
   },
   "source": [
    "#  seq2seq + attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDr9hlgWRZm8"
   },
   "source": [
    "![s2s_attention.png](../data/s2s_attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nCJXJp6RZm9"
   },
   "source": [
    "- EO : encoder 各个位置的输出  \n",
    "\n",
    "\n",
    "- H : decoder 某一步的隐含状态 \n",
    "\n",
    "\n",
    "- FC : 全连阶层 \n",
    "\n",
    "\n",
    "- X : decoder 的一个输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ra-0dKWRZm_"
   },
   "source": [
    "- [Bahdanau 注意力] score = FC(tanh(FC(EO) + FC(H))) \n",
    "- [luong 注意力] score = EO\\*W\\*H \n",
    "\n",
    "\n",
    "- attention_weights = softmax(score,axis = 1)\n",
    "- context = sum(attention_weights * EO, axis = 1)\n",
    "- final_input = concat(context,embed(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tAYyK9URZnA"
   },
   "source": [
    "# seq2seq + attention 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注:以下是在google colab 上GPU跑的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zgfiGQZRZnD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WLD2VzSRZnL"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGJWmf2TRZnT"
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "h2rmSKf1X9Eg",
    "outputId": "3d304608-a50c-4ce1-e06b-da9b777244d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uol5g42sRZnb"
   },
   "outputs": [],
   "source": [
    "file = \"/content/drive/My Drive/cmn.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LX7SrmWYRZnh"
   },
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xi5_2tzURZni"
   },
   "source": [
    "### 数据查看 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1nY7mrCRZnj"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.lower().strip()\n",
    "\n",
    "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
    "    # https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-tux1j5RZnq"
   },
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "979ySdlURZnx"
   },
   "outputs": [],
   "source": [
    "en_data, cn_data, _ = read_txt(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "KI3W-gESRZn2",
    "outputId": "0684a286-d3de-4b48-976f-6f051783190f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('我母亲的法语比我父亲的英语要好，所以他们通常用法语交流。',\n",
       " '汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。',\n",
       " '即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。',\n",
       " '你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。',\n",
       " '如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "NtWKp2WtRZn_",
    "outputId": "c47faa58-da52-46ba-d3b8-11d8cc048f2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.738 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "cn_data = [\" \".join(jieba.cut(x, cut_all=False)) for x in cn_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "ThhH_w0dRZoH",
    "outputId": "883ee965-c1e4-45e0-c9d0-db3b756584ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我 母亲 的 法语 比 我 父亲 的 英语 要 好 ， 所以 他们 通常 用 法语 交流 。',\n",
       " '汤姆 不知 如何 翻译 “ 计算机 ” 一词 ， 因为 同 他 谈话 的 人 从未见过 一台 。',\n",
       " '即使 是 现在 ， 我 偶尔 还是 想 见到 你 。 不是 今天 的 你 ， 而是 我 记忆 中 曾经 的 你 。',\n",
       " '你 很 容易 把 母语 说 得 通顺 流畅 ， 却 很 容易 把 非 母语 说 得 不 自然 。',\n",
       " '如果 一個 人 在 成人 前 沒 有 機會習 得 目標 語言 ， 他 對 該 語言 的 認識 達 到 母語者 程度 的 機會 是 相當 小 的 。']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXc2SvF4RZoO"
   },
   "outputs": [],
   "source": [
    "# 给句子加上开始和结束标记\n",
    "# 以便模型知道何时开始和结束预测\n",
    "en_data = ['<start> ' + w + ' <end>' for w in en_data]\n",
    "cn_data = ['<start> ' + w + ' <end>' for w in cn_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "n94o5ekWRZoS",
    "outputId": "640e5ada-dc7b-4ca2-bd86-6b1a3f913885"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<start> my mother speaks french better than my father speaks english , so they usually speak to each other in french . <end>',\n",
       "  \"<start> tom didn't know how to translate the word computer because the people he was talking to had never seen one . <end>\",\n",
       "  \"<start> even now , i occasionally think i'd like to see you . not the you that you are today , but the you i remember from the past . <end>\",\n",
       "  \"<start> it's very easy to sound natural in your own native language , and very easy to sound unnatural in your non-native language . <end>\",\n",
       "  \"<start> if a person has not had a chance to acquire his target language by the time he's an adult , he's unlikely to be able to reach native speaker level in that language . <end>\"],\n",
       " ['<start> 我 母亲 的 法语 比 我 父亲 的 英语 要 好 ， 所以 他们 通常 用 法语 交流 。 <end>',\n",
       "  '<start> 汤姆 不知 如何 翻译 “ 计算机 ” 一词 ， 因为 同 他 谈话 的 人 从未见过 一台 。 <end>',\n",
       "  '<start> 即使 是 现在 ， 我 偶尔 还是 想 见到 你 。 不是 今天 的 你 ， 而是 我 记忆 中 曾经 的 你 。 <end>',\n",
       "  '<start> 你 很 容易 把 母语 说 得 通顺 流畅 ， 却 很 容易 把 非 母语 说 得 不 自然 。 <end>',\n",
       "  '<start> 如果 一個 人 在 成人 前 沒 有 機會習 得 目標 語言 ， 他 對 該 語言 的 認識 達 到 母語者 程度 的 機會 是 相當 小 的 。 <end>'])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data[-5:],cn_data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMRCOjtMRZob"
   },
   "outputs": [],
   "source": [
    "lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7YjBfpSRZof"
   },
   "outputs": [],
   "source": [
    "lang_tokenizer.fit_on_texts(cn_data[:3])\n",
    "tensor = lang_tokenizer.texts_to_sequences(cn_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDCwL7QFRZoo"
   },
   "outputs": [],
   "source": [
    "tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "SI8i140QRZov",
    "outputId": "2266532c-d67a-406e-c64d-230172d8337b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 2, 3, 0, 0, 0],\n",
       "       [1, 5, 2, 3, 0, 0, 0],\n",
       "       [1, 6, 7, 8, 9, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "96OQaXKDRZo0",
    "outputId": "0a24a6d0-c78f-4553-dc8d-0871a10d5d20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<end>': 3,\n",
       " '<start>': 1,\n",
       " '。': 2,\n",
       " '你': 6,\n",
       " '你好': 5,\n",
       " '嗨': 4,\n",
       " '用': 7,\n",
       " '的': 9,\n",
       " '跑': 8}"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFTxAhrKRZo5"
   },
   "source": [
    "### 创建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzt0djnPRZo7"
   },
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    tokenizer.fit_on_texts(txt)\n",
    "    tensor = tokenizer.texts_to_sequences(txt)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roDwZZGCRZpA"
   },
   "outputs": [],
   "source": [
    "en_tensor, en_tokenizer = tokenize(en_data)\n",
    "cn_tensor, cn_tokenizer = tokenize(cn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6YqzHjbvRZpF"
   },
   "outputs": [],
   "source": [
    "en_tensor_length, cn_tensor_length = en_tensor.shape[1], cn_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Fv2xnRwRRZpK",
    "outputId": "6a1d562f-f3dc-4733-d318-9bb7919ccdb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tensor_length, cn_tensor_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOOj2PQFRZpR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtfoLjsfRZpW"
   },
   "outputs": [],
   "source": [
    "en_tensor_train, en_tensor_val, cn_tensor_train, cn_tensor_val = train_test_split(en_tensor, cn_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qOGhfx3xRZpb",
    "outputId": "b8e04b82-4d73-43ff-cc5c-0c86888a25c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18755, 36), (4689, 36))"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tensor_train.shape, en_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ejwwv-mRZpi"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(en_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "\n",
    "vocab_en_size = len(en_tokenizer.word_index)+1\n",
    "vocab_cn_size = len(cn_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((en_tensor_train, cn_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GK8N4x9CRZpn",
    "outputId": "985febfd-23c9-4f58-b2e5-8867732ef254"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 36]), TensorShape([64, 32]))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_en_batch, example_cn_batch = next(iter(dataset))\n",
    "example_en_batch.shape, example_cn_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZHPKRVgRZpq"
   },
   "outputs": [],
   "source": [
    "vocab_en_size = len(en_tokenizer.word_index)+1\n",
    "vocab_cn_size = len(cn_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kmwaBM4RZpx"
   },
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhNTSHyLRZpx"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True, # return all the hidden state outputs；[batch,x_length,units]\n",
    "                                   return_state=True, #return the last hidden state output；[batch,units]\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, init_hidden):\n",
    "        x = self.embedding(x)\n",
    "        hiddens, last = self.gru(x, initial_state = init_hidden)\n",
    "        return hiddens, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TMUQbffERZp1"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWquX67mRZp4"
   },
   "outputs": [],
   "source": [
    "hidden_initializer = tf.zeros((BATCH_SIZE, units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwNNFMIRRZp7"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_en_size, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9C93uUdpRZqV"
   },
   "outputs": [],
   "source": [
    "sample_encoder_output, sample_encoder_lst = encoder(example_en_batch,hidden_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zytHSgRORZqa",
    "outputId": "acc3036c-96bb-4e1a-a086-dcd9e356d9a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_en_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rludcqRmRZqi",
    "outputId": "654f059b-f9fe-4784-8197-d1fa941d6028"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 36, 1000]), TensorShape([64, 1000]))"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_output.shape,sample_encoder_lst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NarYMMwARZqm"
   },
   "source": [
    "# Bahdanau Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eI3arIJcRZqn"
   },
   "source": [
    "\n",
    "EO : encoder 各个位置的输出\n",
    "\n",
    "H : decoder 某一步的隐含状态\n",
    "\n",
    "[Bahdanau 注意力] score = FC(tanh(FC(EO) + FC(H))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXngub7wRZqo"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, last_output, hiddens):\n",
    "        last_output_with_time_axis = tf.expand_dims(last_output, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(hiddens) + self.W2(last_output_with_time_axis)))\n",
    "\n",
    "        # shape:(batch_size, length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector.shape :(batch_size, length, units)\n",
    "        context_vector = attention_weights * hiddens\n",
    "\n",
    "        # context_vector.shape :(batch_size, units)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SG5B45MpRZqs"
   },
   "outputs": [],
   "source": [
    "attention = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention(sample_encoder_lst, sample_encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2M0eolFuRZqu",
    "outputId": "f7dc6e31-1697-4acf-a1ec-9cfea9e6bc4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 1000]), TensorShape([64, 36, 1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_result.shape,attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYaibJzERZqy"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    \n",
    "    def call(self, x, en_last_output, en_hiddens):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(en_last_output, en_hiddens)\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        #print(x.shape)\n",
    "        output, state = self.gru(x)\n",
    "        #print(output.shape)\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMi9VAncRZq1"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1000\n",
    "decoder = Decoder(vocab_cn_size, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9482aGU7RZq4"
   },
   "outputs": [],
   "source": [
    "sample_decoder_output, _, _ = decoder(tf.expand_dims(example_cn_batch[...,1], -1),\n",
    "                                      sample_encoder_lst, sample_encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "PtLl_Md7RZq8",
    "outputId": "5e2490f8-ee21-40c3-8dbb-dc31a3ec17c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 14490), dtype=float32, numpy=\n",
       "array([[-8.9625141e-04, -2.0650481e-03,  1.4418727e-04, ...,\n",
       "        -4.8619256e-04,  7.0079265e-04,  1.7073995e-04],\n",
       "       [-2.3152698e-03, -2.8430824e-03, -9.4862672e-04, ...,\n",
       "         4.8295050e-03,  3.3216036e-04,  1.9666724e-04],\n",
       "       [-8.1448827e-04, -2.1365557e-03,  1.3786015e-05, ...,\n",
       "        -6.9960975e-04,  7.5361761e-04, -5.3609720e-06],\n",
       "       ...,\n",
       "       [-1.7005488e-03,  1.8617237e-03,  1.4689261e-03, ...,\n",
       "         3.3776503e-04,  3.3742061e-04, -1.4049484e-03],\n",
       "       [-5.2604056e-04, -4.9776379e-05, -1.6909594e-03, ...,\n",
       "         4.0681385e-03, -8.1996905e-04, -5.3315624e-03],\n",
       "       [-1.2560968e-03,  7.0743688e-04, -1.1438805e-03, ...,\n",
       "        -1.3315986e-03, -9.7000704e-04, -7.1235624e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "To2SbncvRZrB"
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXKhwBmPRZrB"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSB5OSAS25Kn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yv9U08--RZrL"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-04977c30b5f0>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-04977c30b5f0>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    dec_input = tf.expand_dims([cn_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_hiddens, enc_last = encoder(inp, enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([cn_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        targ_len = targ.shape[1]\n",
    "\n",
    "        for t in range(1, targ_len):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, enc_last, enc_hiddens)\n",
    "            mask = tf.cast(tf.math.logical_not(tf.math.equal(targ[:, t], 0)), dtype = tf.float32)\n",
    "            loss_ = 0.0\n",
    "            loss_ = SparseCategoricalCrossentropy(from_logits=True, reduction='none')(targ[:, t], predictions)\n",
    "            loss_ *= mask #除去pad\n",
    "            loss_ = tf.reduce_mean(loss_)\n",
    "            loss += loss_\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    loss_mean = (loss / int(targ_len))\n",
    "    \n",
    "    return loss_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJQYpN3ld3Cv"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "jNp6P2-NRZrU",
    "outputId": "e8f29826-92d1-4315-ec3e-45fcf812ef08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.3683\n",
      "Epoch 2 Loss 1.1301\n",
      "Epoch 3 Loss 0.9585\n",
      "Epoch 4 Loss 0.8010\n",
      "Epoch 5 Loss 0.6365\n",
      "Epoch 6 Loss 0.4723\n",
      "Epoch 7 Loss 0.3324\n",
      "Epoch 8 Loss 0.2292\n",
      "Epoch 9 Loss 0.1584\n",
      "Epoch 10 Loss 0.1117\n",
      "Epoch 11 Loss 0.0814\n",
      "Epoch 12 Loss 0.0613\n",
      "Epoch 13 Loss 0.0472\n",
      "Epoch 14 Loss 0.0387\n",
      "Epoch 15 Loss 0.0326\n",
      "Epoch 16 Loss 0.0277\n",
      "Epoch 17 Loss 0.0255\n",
      "Epoch 18 Loss 0.0235\n",
      "Epoch 19 Loss 0.0233\n",
      "Epoch 20 Loss 0.0245\n",
      "CPU times: user 42min 40s, sys: 22min 27s, total: 1h 5min 8s\n",
      "Wall time: 1h 17min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 20\n",
    "enc_hidden_initializer = tf.zeros((BATCH_SIZE, units))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for (batch_id, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden_initializer)\n",
    "        total_loss += batch_loss\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / steps_per_epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kxs5ZJkYP5mc"
   },
   "outputs": [],
   "source": [
    "# batch = 1\n",
    "def translate(inputs):\n",
    "    result = ''\n",
    "    # batch = 1\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([cn_tokenizer.word_index['<start>']], 1)\n",
    "\n",
    "    for t in range(cn_tensor_length):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,dec_hidden,enc_out)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions,1).numpy()[0]\n",
    "\n",
    "        result += cn_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if cn_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0bsgNGcir0Q1"
   },
   "outputs": [],
   "source": [
    "def tensor_to_str(tensor,en_tokenizer):\n",
    "    str_lst = ' '.join(en_tokenizer.sequences_to_texts(np.expand_dims(tensor,-1)))\n",
    "    return str_lst.split('<end>')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Wi7P3fyZtXps",
    "outputId": "3137cdcc-5390-4345-d731-65844d262264"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> she was frequently late for school . '"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_to_str(en_tensor_val[0],en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RUxE1iRDYACY",
    "outputId": "52b78c7b-8213-4761-f7f6-d58e6800a745"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'她 經常上 學遲 到 。 <end> '"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(en_tensor_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "WqUu20J4vqir",
    "outputId": "ff83ad4a-51d1-43fa-96b3-c818b3e14b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> she was frequently late for school . \n",
      "她 經常上 學遲 到 。 <end> \n",
      "<start> man is mortal . \n",
      "人 都 是 綠燈 。 <end> \n",
      "<start> tom can't remember anything . \n",
      "湯姆 不能 再 做 任何 事 。 <end> \n",
      "<start> all of you are familiar with the truth of the story . \n",
      "你們 所有 的 故事 故事 都 很 开心 。 <end> \n",
      "<start> your memory is good . \n",
      "您 记性 很 好 。 <end> \n",
      "<start> the dog attacked the little boy . \n",
      "這 隻 男孩 救 了 這個 小女孩 。 <end> \n",
      "<start> smoking is not allowed here . \n",
      "不允許 在 這裡 。 <end> \n",
      "<start> is it cheaper to call after 9:00 ? \n",
      "最近 的 时候 後 的 时候 是 去 钓鱼 嗎 ？ <end> \n",
      "<start> he comes back from sydney today . \n",
      "他 今天 会 下雪 。 <end> \n",
      "<start> i do not want any bananas at all . \n",
      "我 一個 香蕉 也 不要 。 <end> \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(tensor_to_str(en_tensor_val[i],en_tokenizer))\n",
    "    print(translate(en_tensor_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJEk-pn7vquL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_VFzvZUvqg1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq + attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
