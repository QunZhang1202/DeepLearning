{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eileen Zhang 2020/8/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![deepfm](../data/deepfm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer,Dense,Embedding,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(Layer):\n",
    "    def __init__(self, units, dropout = 0.8, output_layer=True):\n",
    "        super().__init__()\n",
    "        self.output_layer = output_layer\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.bns = [BatchNormalization() for i in range(len(units))]\n",
    "        self.denses = [Dense(u,activation = 'relu') for u in units]\n",
    "        if output_layer:\n",
    "            self.denses.append(Dense(1))\n",
    "     \n",
    "    def build(self, input_shape):    \n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        for bn, dense in zip(self.bns,self.denses) :\n",
    "            inputs = bn(inputs,training)\n",
    "            inputs = dense(inputs)\n",
    "            if training:\n",
    "                inputs = self.dropout_layer(inputs, training=training)\n",
    "        if self.output_layer:\n",
    "            inputs = self.denses[-1](inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldAwareFactorizationMachine(Layer):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    def __init__(self, field_dim_groups, embed_dim):\n",
    "        \"\"\"\n",
    "        :param x: field_dim_groups features group(the max_len for features)eg: [[10,20,40],[20,30,10],[5,6]]]``\n",
    "                  num_field_groups : [0,3,6]``\n",
    "        \n",
    "        \"\"\"        \n",
    "        super().__init__()\n",
    "        self.field_dim_groups = field_dim_groups\n",
    "        self.features_len = np.sum([len(x) for x in field_dim_groups])\n",
    "        self.num_field_groups = np.cumsum([0] + [len(x) for x in field_dim_groups])[:-1]\n",
    "        #for irregular list [[10,20,40],[20,30,10],[5,6]]]\n",
    "        self.maxlen = np.sum(np.sum(field_dim_groups))\n",
    "        self.embeddings = Embedding(self.maxlen, embed_dim)\n",
    "        self.offsets = tf.constant(np.expand_dims(np.array((0, *np.cumsum([x for y in field_dim_groups for x in y])[:-1]), dtype=np.float32),0))\n",
    "\n",
    "    def build(self, input_shape):    \n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + self.offsets\n",
    "        x = self.embeddings(x)\n",
    "        ix = []\n",
    "        for i in range(len(self.field_dim_groups) - 1):           \n",
    "            for j in range(self.num_field_groups[i], self.num_field_groups[i + 1]):\n",
    "                ix += [x[:, j, : ] * x[:, k, :] for k in range(self.num_field_groups[i + 1], self.features_len)]\n",
    "        ix = tf.stack(ix)\n",
    "        ix = tf.transpose(ix, perm=[1, 0, 2])\n",
    "        return tf.concat([x, ix],1), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFactorizationMachineModel(Model):\n",
    "    \"\"\"\n",
    "    A keras implementation of DeepFM.\n",
    "\n",
    "    Reference:\n",
    "        H Guo, et al. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, 2017.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dim_groups, embed_dim, units = [100,50]):\n",
    "        super().__init__()\n",
    "        units = units + [embed_dim]\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ffm = FieldAwareFactorizationMachine(field_dim_groups, embed_dim)\n",
    "        self.mlp = MultiLayerPerceptron(units,output_layer = False)\n",
    "        self.dense = Dense(1)\n",
    "        self.fc = Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x_ffm, x = self.ffm(x)\n",
    "        x_mlp = self.mlp(x)     \n",
    "        out = tf.concat([x_ffm,x_mlp],1)\n",
    "        out = tf.squeeze(self.dense(out),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFactorizationMachineModel([[10,20,40],[50,51]],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.],\n",
       "       [10., 20., 30., 40., 50.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.constant([[0.,1.,2.,3.,4.],[10.,20.,30.,40.,50.]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.504937  ],\n",
       "       [0.49564382]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_factorization_machine_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "field_aware_factorization_ma multiple                  513       \n",
      "_________________________________________________________________\n",
      "multi_layer_perceptron (Mult multiple                  6215      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  4         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  17        \n",
      "=================================================================\n",
      "Total params: 6,749\n",
      "Trainable params: 6,443\n",
      "Non-trainable params: 306\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
